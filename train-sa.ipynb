{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T10:03:50.938213Z",
     "start_time": "2024-12-08T10:03:48.865427Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers datasets torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9fed3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56350dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import hf_xet\n",
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c4afaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c9f6c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8abdc670d600d68e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T10:04:00.727244Z",
     "start_time": "2024-12-08T10:03:50.953216Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets.arrow_dataset import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26fc7a2d5a745970",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T10:04:01.007761Z",
     "start_time": "2024-12-08T10:04:00.968479Z"
    }
   },
   "outputs": [],
   "source": [
    "# Đọc dữ liệu\n",
    "df = pd.read_csv('./data/balanced_neutral_sentiment_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65df971a26fa5e73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T10:04:01.053623Z",
     "start_time": "2024-12-08T10:04:01.023702Z"
    }
   },
   "outputs": [],
   "source": [
    "# Kiểm tra kiểu dữ liệu và xử lý missing values\n",
    "df['cleaned_comment'] = df['cleaned_comment'].astype(str)\n",
    "df['cleaned_comment'] = df['cleaned_comment'].fillna('')\n",
    "\n",
    "# Chia dữ liệu thành train, validation, test\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.125, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df[['cleaned_comment', 'sentiment']])\n",
    "val_dataset = Dataset.from_pandas(val_df[['cleaned_comment', 'sentiment']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['cleaned_comment', 'sentiment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d56a8d6da9b94a50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T10:04:05.543044Z",
     "start_time": "2024-12-08T10:04:01.064572Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2715/2715 [00:01<00:00, 1680.04 examples/s]\n",
      "Map: 100%|██████████| 388/388 [00:00<00:00, 1783.35 examples/s]\n",
      "Map: 100%|██████████| 776/776 [00:00<00:00, 1738.14 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tải BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Hàm token hóa dữ liệu\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['cleaned_comment'], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bd7cfae33eb3dae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T10:04:05.609319Z",
     "start_time": "2024-12-08T10:04:05.556551Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2715/2715 [00:00<00:00, 126110.60 examples/s]\n",
      "Map: 100%|██████████| 388/388 [00:00<00:00, 50439.81 examples/s]\n",
      "Map: 100%|██████████| 776/776 [00:00<00:00, 97749.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cleaned_comment': 'bênh viện còn khá mới, nhân viên tận tình nhẹ nhàng. nhưng điều quan truyền nhất là bác sỹ trẻ nhiều quá, bác sỹ thực hành nhưng lại không có thạc sỹ bác sỹ hay bác sỹ ckii phụ trách chính. bác sỹ trẻ thăm khám trực tiếp rất thiếu kinh nghiệm, phải có bác sỹ phụ trách khoa kèm cặp và ra quyết định.', 'sentiment': 'Trung tính', '__index_level_0__': 2899, 'input_ids': [101, 24429, 10237, 27805, 14674, 57205, 18652, 117, 14694, 15202, 109327, 23403, 93799, 13265, 10376, 119, 15662, 16391, 12522, 20967, 13346, 10331, 98709, 187, 66556, 38723, 13710, 27261, 117, 98709, 187, 66556, 11992, 13910, 15662, 13148, 11755, 10601, 77586, 31607, 187, 66556, 98709, 187, 66556, 13605, 98709, 187, 66556, 171, 70149, 28422, 59660, 12707, 119, 98709, 187, 66556, 38723, 89311, 57205, 10147, 34270, 16948, 18946, 54594, 21130, 42788, 117, 15723, 10601, 98709, 187, 66556, 28422, 59660, 11685, 179, 70958, 171, 75669, 10432, 11859, 27016, 15027, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Mã hóa nhãn\n",
    "label_mapping = {'Tốt': 2, 'Trung tính': 1, 'Tệ': 0}\n",
    "\n",
    "def label_mapping_function(examples):\n",
    "    examples['label'] = [label_mapping[sentiment] for sentiment in examples['sentiment']]\n",
    "    return examples\n",
    "\n",
    "train_dataset = train_dataset.map(label_mapping_function, batched=True)\n",
    "val_dataset = val_dataset.map(label_mapping_function, batched=True)\n",
    "test_dataset = test_dataset.map(label_mapping_function, batched=True)\n",
    "\n",
    "# Kiểm tra kết quả\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a859e585e59a6708",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T10:04:05.689380Z",
     "start_time": "2024-12-08T10:04:05.683430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng mẫu trong tập train:\n",
      "sentiment\n",
      "Tốt           1108\n",
      "Tệ             895\n",
      "Trung tính     712\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Số lượng mẫu trong tập validation:\n",
      "sentiment\n",
      "Tốt           169\n",
      "Tệ            117\n",
      "Trung tính    102\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Số lượng mẫu trong tập test:\n",
      "sentiment\n",
      "Tốt           333\n",
      "Tệ            257\n",
      "Trung tính    186\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra số lượng mẫu cân bằng\n",
    "print(\"Số lượng mẫu trong tập train:\")\n",
    "print(train_df['sentiment'].value_counts())\n",
    "print(\"\\nSố lượng mẫu trong tập validation:\")\n",
    "print(val_df['sentiment'].value_counts())\n",
    "print(\"\\nSố lượng mẫu trong tập test:\")\n",
    "print(test_df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8676521635d801f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T10:04:09.529904Z",
     "start_time": "2024-12-08T10:04:08.440546Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=3)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8c8377a2d7e58e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T10:04:09.689962Z",
     "start_time": "2024-12-08T10:04:09.685908Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds, labels = p\n",
    "    preds = preds.argmax(axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e363e29a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m.safetensors.items(\u001b[32m0\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eca068da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.3\n"
     ]
    }
   ],
   "source": [
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c9d6ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerate version: 1.6.0\n",
      "Transformers version: 4.51.3\n"
     ]
    }
   ],
   "source": [
    "print(\"Accelerate version:\", accelerate.__version__)\n",
    "print(\"Transformers version:\", transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a440d20843336fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T10:04:11.713579Z",
     "start_time": "2024-12-08T10:04:11.600945Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',                  \n",
    "    eval_strategy=\"epoch\",             \n",
    "    save_strategy=\"epoch\",                   \n",
    "    learning_rate=2e-5,                      \n",
    "    per_device_train_batch_size=16,          \n",
    "    per_device_eval_batch_size=64,           \n",
    "    num_train_epochs=10,                     \n",
    "    weight_decay=0.01,                       \n",
    "    logging_dir='./logs',                    \n",
    "    load_best_model_at_end=True,             \n",
    "    fp16=True,                               \n",
    "    gradient_accumulation_steps=2,           \n",
    "    save_steps=1000,                         \n",
    "    eval_steps=1000,                         \n",
    "    save_total_limit=3,                      \n",
    "    logging_steps=500,                       \n",
    ")\n",
    "# Cài đặt Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                            \n",
    "    args=training_args,                     \n",
    "    train_dataset=train_dataset,            \n",
    "    eval_dataset=val_dataset,               \n",
    "    compute_metrics=compute_metrics,         \n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40664f69d9e0d8b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T11:51:47.287186Z",
     "start_time": "2024-12-08T10:04:18.813413Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='680' max='850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [680/850 5:10:55 < 1:17:57, 0.04 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.368307</td>\n",
       "      <td>0.878866</td>\n",
       "      <td>0.889189</td>\n",
       "      <td>0.878866</td>\n",
       "      <td>0.878393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.330908</td>\n",
       "      <td>0.891753</td>\n",
       "      <td>0.899770</td>\n",
       "      <td>0.891753</td>\n",
       "      <td>0.891023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.284252</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.891818</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.886334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300786</td>\n",
       "      <td>0.876289</td>\n",
       "      <td>0.878361</td>\n",
       "      <td>0.876289</td>\n",
       "      <td>0.876510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.412529</td>\n",
       "      <td>0.873711</td>\n",
       "      <td>0.878168</td>\n",
       "      <td>0.873711</td>\n",
       "      <td>0.874263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.297800</td>\n",
       "      <td>0.414189</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.888197</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.886019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.297800</td>\n",
       "      <td>0.465927</td>\n",
       "      <td>0.891753</td>\n",
       "      <td>0.891230</td>\n",
       "      <td>0.891753</td>\n",
       "      <td>0.891004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.297800</td>\n",
       "      <td>0.527854</td>\n",
       "      <td>0.894330</td>\n",
       "      <td>0.894352</td>\n",
       "      <td>0.894330</td>\n",
       "      <td>0.893703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=680, training_loss=0.2413575999877032, metrics={'train_runtime': 18689.2824, 'train_samples_per_second': 1.453, 'train_steps_per_second': 0.045, 'total_flos': 1428705858263040.0, 'train_loss': 0.2413575999877032, 'epoch': 8.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huấn luyện mô hình\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0b47ccda1af3cd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T11:52:37.051523Z",
     "start_time": "2024-12-08T11:51:47.394189Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 01:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3382989466190338, 'eval_accuracy': 0.8827319587628866, 'eval_precision': 0.8873570877436858, 'eval_recall': 0.8827319587628866, 'eval_f1': 0.8826269630453241, 'eval_runtime': 125.4606, 'eval_samples_per_second': 6.185, 'eval_steps_per_second': 0.104, 'epoch': 8.0}\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá mô hình\n",
    "results = trainer.evaluate(test_dataset)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bce16cff17f00b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T13:26:24.707128Z",
     "start_time": "2024-12-09T13:26:24.668217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cảm xúc dự đoán: Tệ\n"
     ]
    }
   ],
   "source": [
    "# Hàm dự đoán cảm xúc\n",
    "def predict_sentiment(text):\n",
    "    enc = tokenizer(text, truncation=True, padding=True, max_length=128, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(**enc)\n",
    "    pred = torch.argmax(output.logits, dim=-1)\n",
    "    return pred.item()\n",
    "\n",
    "# Dự đoán một ví dụ\n",
    "new_comment = \"Bệnh viện sạch, y tá có thái độ với bệnh nhân\"\n",
    "prediction = predict_sentiment(new_comment)\n",
    "sentiment_labels = ['Tệ', 'Trung tính', 'Tốt']\n",
    "print(f\"Cảm xúc dự đoán: {sentiment_labels[prediction]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8947978671ef37d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T10:58:46.831804Z",
     "start_time": "2024-12-09T10:58:46.826804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([2, 0], 1.0)\n"
     ]
    }
   ],
   "source": [
    "def split_clauses(sentence):\n",
    "    import re\n",
    "    clauses = re.split(r'[,.;!?]', sentence)\n",
    "    return [clauses.strip() for clauses in clauses if clauses.strip()]\n",
    "\n",
    "def score_sentence(sentence):\n",
    "    clauses = split_clauses(sentence)\n",
    "    if not clauses:\n",
    "        return None,\n",
    "    \n",
    "    scores = []\n",
    "    for clause in clauses:\n",
    "        pred = predict_sentiment(clause)\n",
    "        scores.append(pred)\n",
    "        \n",
    "    overall_score = sum(scores) / len(scores)\n",
    "    return scores, overall_score\n",
    "\n",
    "sentence = \"Bệnh viện sạch, y tá có thái độ với bệnh nhân\"\n",
    "overall_score = score_sentence(sentence)\n",
    "print(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cb8acfb15b3c0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sentiment_model_bert\\\\tokenizer_config.json',\n",
       " 'sentiment_model_bert\\\\special_tokens_map.json',\n",
       " 'sentiment_model_bert\\\\vocab.txt',\n",
       " 'sentiment_model_bert\\\\added_tokens.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Giả sử mô hình đã được huấn luyện là model\n",
    "model.save_pretrained(\"sentiment_model_bert\")\n",
    "tokenizer.save_pretrained(\"sentiment_model_bert\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
