import streamlit as st
import torch
from transformers import BertTokenizer, BertForSequenceClassification
import re

# Load model and tokenizer
@st.cache_resource
def load_model():
    
    model = BertForSequenceClassification.from_pretrained("sentiment_model_bert")
    tokenizer = BertTokenizer.from_pretrained("sentiment_model_bert")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    model.eval()
    return model, tokenizer, device

model, tokenizer, device = load_model()

# D·ª± ƒëo√°n c·∫£m x√∫c cho m·ªôt ƒëo·∫°n vƒÉn ho·∫∑c m·ªánh ƒë·ªÅ
def predict_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128).to(device)
    with torch.no_grad():
        outputs = model(**inputs)
    logits = outputs.logits
    prediction = torch.argmax(logits, dim=1).item()
    return prediction  # 0: T·ªá, 1: Trung t√≠nh, 2: T·ªët

# Chia c√¢u th√†nh c√°c m·ªánh ƒë·ªÅ
def split_clauses(sentence):
    clauses = re.split(r'[,.;!?]', sentence)
    return [clause.strip() for clause in clauses if clause.strip()]

# D·ª± ƒëo√°n theo t·ª´ng m·ªánh ƒë·ªÅ v√† t√≠nh trung b√¨nh
def score_sentence(sentence):
    clauses = split_clauses(sentence)
    if not clauses:
        return [], None
    scores = [predict_sentiment(clause) for clause in clauses]
    avg_score = sum(scores) / len(scores)
    return scores, avg_score

# Giao di·ªán Streamlit
st.title("Ph√¢n t√≠ch c·∫£m x√∫c c√¢u ti·∫øng Vi·ªát")

sentence = st.text_area("Nh·∫≠p c√¢u ho·∫∑c ƒëo·∫°n vƒÉn:", "B·ªánh vi·ªán s·∫°ch, y t√° c√≥ th√°i ƒë·ªô v·ªõi b·ªánh nh√¢n")

if st.button("D·ª± ƒëo√°n"):
    st.markdown("### üîπ K·∫øt qu·∫£ d·ª± ƒëo√°n theo to√†n c√¢u:")
    full_pred = predict_sentiment(sentence)
    st.write(f"\- D·ª± ƒëo√°n: {['T·ªá', 'Trung t√≠nh', 'T·ªët'][full_pred]}")

    st.markdown("### üî∏ K·∫øt qu·∫£ d·ª± ƒëo√°n theo t·ª´ng m·ªánh ƒë·ªÅ:")
    scores, avg = score_sentence(sentence)
    if scores:
        for idx, (clause, score) in enumerate(zip(split_clauses(sentence), scores)):
            st.write(f"\- M·ªánh ƒë·ªÅ {idx+1}: '{clause}' ‚Üí {['T·ªá', 'Trung t√≠nh', 'T·ªët'][score]}")
        st.write(f"\nTrung b√¨nh: {avg:.2f} ‚Üí {['T·ªá', 'Trung t√≠nh', 'T·ªët'][round(avg)]}")
    else:
        st.warning("Kh√¥ng th·ªÉ t√°ch c√¢u th√†nh m·ªánh ƒë·ªÅ h·ª£p l·ªá.")

st.markdown()

# import streamlit as st
# from transformers import BertTokenizer, BertForSequenceClassification
# import torch
# import torch.nn.functional as F

# # Load m√¥ h√¨nh v√† tokenizer
# @st.cache_resource
# def load_model():
#     model = BertForSequenceClassification.from_pretrained("sentiment_model_bert")
#     tokenizer = BertTokenizer.from_pretrained("bert-base-multilingual-cased")
#     return model, tokenizer

# model, tokenizer = load_model()
# model.eval()

# # Label mapping
# id2label = {0: "T·ªá", 1: "Trung t√≠nh", 2: "T·ªët"}

# # Giao di·ªán Streamlit
# st.title("Ph√¢n t√≠ch c·∫£m x√∫c b√¨nh lu·∫≠n")

# comment = st.text_area("Nh·∫≠p b√¨nh lu·∫≠n c·ªßa b·∫°n:", height=150)

# if st.button("Ph√¢n t√≠ch c·∫£m x√∫c"):
#     if not comment.strip():
#         st.warning("Vui l√≤ng nh·∫≠p b√¨nh lu·∫≠n!")
#     else:
#         # Tokenize ƒë·∫ßu v√†o
#         inputs = tokenizer(comment, return_tensors="pt", truncation=True, padding=True, max_length=128)
#         with torch.no_grad():
#             outputs = model(**inputs)
#             probs = F.softmax(outputs.logits, dim=1)
#             pred_label = torch.argmax(probs, dim=1).item()
        
#         st.subheader("K·∫øt qu·∫£:")
#         st.write(f"**D·ª± ƒëo√°n:** {id2label[pred_label]}")
        
#         st.write("**X√°c su·∫•t:**")
#         for i in range(3):
#             st.write(f"- {id2label[i]}: {probs[0][i].item():.4f}")

